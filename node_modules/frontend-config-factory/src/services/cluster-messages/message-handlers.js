const { join } = require('path');
const os = require('os');
const fs = require('fs');
const restclient = require('frontend-restclient');
const { fetchRemoteConfigFile } = require('../fetch-remote-config-file');
const REST_CLIENT_CONFIG = require('../../constants/rest-client-config');
const deepMerge = require('../deep-merge');
const cluster = require('.');
const { DELETING_BETA_CONFIG_FILE, ERROR_LISTENERS_THRESHOLD, ERROR_WRITING_FILE_TO_DISK, ERROR_READING_FILE_FROM_DISK, ERROR_DELETING_FILE_FROM_DISK } = require('../../constants/stats');
const { CONFIG_FOLDER, CONFIG_SAVED, MASTER_FAIL_WRITING_FILE, MASTER_FETCH_NEW_ENVIRONMENT, REMOVE_ENV_DATA, FETCH_ALL_ENVS } = require('../../constants/cluster-variables');
const { A_WEEK } = require('../../constants/intervals');
const { production } = require('../../constants/environment-variables');


const messagesHandler = (configData, {
  logger,
  update,
  restClientConfig,
  onFetched,
  onFetchError,
  packageName,
}) => {
  const folderpath = join(os.tmpdir(), `/${CONFIG_FOLDER}/${packageName}`);
  const restConfig = deepMerge(REST_CLIENT_CONFIG, restClientConfig);
  const restclientInstance = restclient(restConfig);
  const clusterMessages = cluster.startMessaging(packageName);

  /**
   *
   * @returns {boolean} - true if exceeds the percentage allowed of listeners
   */
  const listenersOverThreshold = () => cluster.overThreshold();

  /**
  * Save config data fetched from remote file to disk
  *
  * (Runs only on master)
  * @param {string} environment
  */
  const writeConfigOnDisk = (environment) => {
    const filepath = join(folderpath, `${environment}.json`);
    const messageBody = { environment, module: packageName };
    fs.mkdir(folderpath, { recursive: true }, (mkdirErr) => {
      if (!!mkdirErr && mkdirErr.code !== 'EEXIST') {
        logger.error({
          message: `Error writing folder on disk for config env file: ${environment}`,
          statName: ERROR_WRITING_FILE_TO_DISK,
          extraTags: { environment },
        });
        return clusterMessages.send(MASTER_FAIL_WRITING_FILE, messageBody).toWorkers();
      }
      return fs.writeFile(filepath, JSON.stringify(configData[environment]), {
        flag: 'w',
        encoding: 'utf8',
      }, (writeFileErr) => {
        if (writeFileErr) {
          logger.error({
            message: `Error writing on disk file for config env: ${environment}`,
            statName: ERROR_WRITING_FILE_TO_DISK,
            extraTags: { environment },
          });
          return clusterMessages.send(MASTER_FAIL_WRITING_FILE, messageBody).toWorkers();
        }
        return clusterMessages.send(CONFIG_SAVED, messageBody).toWorkers();
      });
    });
  };

  /**
   * Delete a config environment to prevent store unused files and memory data
   *
   * (Runs only on master)
   * @param {string} environment - Config environment to be deleted from disk and memory
   */
  const deleteEnv = (environment) => {
    delete configData[environment];
    const filepath = join(folderpath, `${environment}.json`);
    fs.unlink(filepath, (err) => {
      if (err) {
        logger.error({
          message: `Error deleting config file ${environment} from disk`,
          statName: ERROR_DELETING_FILE_FROM_DISK,
          extraTags: { environment },
        });
      }
      logger.info({ message: `Deleting config v${environment} after a week`, statName: DELETING_BETA_CONFIG_FILE, extraTags: { environment } });
      clusterMessages.send(`${REMOVE_ENV_DATA}`, { environment, module: packageName }).toWorkers();
    });
  };

  const fetch = ({ environment, req = {}, autoUpdate }) => fetchRemoteConfigFile({
    environment,
    update,
    restclientInstance,
    req,
  })
    .then((response) => {
      if (cluster.isMaster && cluster.hasWorkers()) {
        if (!configData[environment] || configData[environment].version !== response.data.version) {
          writeConfigOnDisk(environment);
        }
        if (environment !== production) {
          setTimeout(() => {
            deleteEnv(environment);
          }, A_WEEK);
        }
      }
      onFetched({ environment, autoUpdate }, response);
    })
    .catch(err => onFetchError({ environment, autoUpdate }, err));

  const handleFetchConfigFile = ({
    environment,
    req,
    autoUpdate,
    catchError,
  }) => {
    const exceedThreshold = listenersOverThreshold();
    if (cluster.isMaster || (cluster.isWorker && exceedThreshold)) {
      if (exceedThreshold) {
        logger.error({
          message: `Listeners of cluster messages exceeds the threshold. ${environment} will be fetched individually for all workers`,
          statName: ERROR_LISTENERS_THRESHOLD,
          extraTags: { environment },
        });
      }
      return fetch({ environment, req, autoUpdate, catchError });
    }
    const messageBody = { environment, req, module: packageName, pid: process.pid.toString() };
    return clusterMessages.send(MASTER_FETCH_NEW_ENVIRONMENT, messageBody).toMaster();
  };
  const getFile = ({
    environment,
    req = null,
    autoUpdate = true,
    catchError = true,
  }) => handleFetchConfigFile({
    environment,
    req,
    autoUpdate,
    catchError,
  });

  const updateConfig = (props = {}) => {
    const { environment, req } = props;
    return fetch({ environment, req });
  };

  /**
  * Handle method for message "`${CONFIG_SAVED}`" sent from master to workers
  * It reads the config file, and if fails, the worker fetch the remote file
  *
  * (Runs only on workers)
  * @param {*} props - messageBody sent on a message
  */
  const onConfigSavedHandler = (props) => {
    const { module, environment } = props || {};
    if (module === packageName && !!environment) {
      const filepath = join(folderpath, `${environment}.json`);
      fs.readFile(filepath, { flag: 'r', encoding: 'utf8' }, (err, dataFromFile) => {
        if (err) {
          // in case of fail reading file, worker will fetch single time the remote config file
          logger.error({
            message: `Worker fail reading file ${environment} from disk`,
            statName: ERROR_READING_FILE_FROM_DISK,
            extraTags: { environment },
          });
          return fetch({ environment, autoUpdate: false });
        }
        onFetched(props, { data: JSON.parse(dataFromFile) });
        return null;
      });
    }
  };

  /**
  * Handle method for message "`${MASTER_FAIL_WRITING_FILE}`" sent from master to workers
  *
  * (Runs only on workers)
  * @param {*} props - messageBody sent on a message
  */
  const onFailWritingFileHandler = (props) => {
    const { module, environment } = props || {};
    if (module === packageName && !!environment) {
      fetch({ environment });
    }
  };

  /**
  * Handle method for message "`${MASTER_FETCH_NEW_ENVIRONMENT}`" sent from worker to master
  *
  * (Runs only on master)
  * @param {*} props - messageBody sent on a message
  */
  const onRequestNewEnvironment = (props) => {
    const { environment, req, module, pid } = props || {};
    if (module === packageName && !!environment) {
      /**
       * Checking if this config environment its in master memory and the file exists
       * Usefull when a new worker is forked after fetch this environment
       */
      if (configData[environment]) {
        const filepath = join(folderpath, `${environment}.json`);
        // Check if file exists
        fs.access(filepath, fs.F_OK, (err) => {
          if (err) {
            // File doesn't exists, save it to disk
            writeConfigOnDisk(environment);
          } else if (environment === production && Object.keys(configData).length > 1) {
            // File exist, send message to read it

            /**
             * If a worker ask for production environment (first ask that workers do to master) and master has more
             * than one environment. The worker that ask for production should try to read all available environments
             * This is usefull for new workers after an old worker died
             */
            const messageBody = {
              pid,
              module: packageName,
              envs: Object.keys(configData),
            };
            clusterMessages.send(FETCH_ALL_ENVS, messageBody).toWorkers();
          } else {
            // Workers should read only asked environment
            const messageBody = { environment, module: packageName };
            clusterMessages.send(CONFIG_SAVED, messageBody).toWorkers();
          }
        });
      } else {
        // fetch new environment
        fetch({
          environment,
          req,
        });
      }
    }
    return null;
  };

  /**
   * Handle method for message "`${REMOVE_ENV_DATA}`" sent from master to workers
   *
   * (Runs only on workers)
   * @param {*} props - messageBody sent on a message
   */
  const onRemoveEnvData = (props) => {
    const { environment, module } = props || {};
    if (module === packageName && !!environment) {
      delete configData[environment];
    }
  };
  /**
   * Handle method for message "${FETCH_ALL_ENVS}" sent from master to workers
   *
   * (Runs only on a single worker matching its pid)
   * @param {*} props - messageBody sent on a message
   */
  const onFetchAllEnvs = (props) => {
    const { pid, module, envs } = props;
    if (module === packageName && pid === process.pid.toString()) {
      envs.map(environment => onConfigSavedHandler({ environment, module }));
    }
  };
  /**
   * Messages being handled
   */
  clusterMessages.handle(`${CONFIG_SAVED}`, onConfigSavedHandler).fromMaster();
  clusterMessages.handle(`${MASTER_FETCH_NEW_ENVIRONMENT}`, onRequestNewEnvironment).fromWorker();
  clusterMessages.handle(`${FETCH_ALL_ENVS}`, onFetchAllEnvs).fromMaster();
  clusterMessages.handle(`${REMOVE_ENV_DATA}`, onRemoveEnvData).fromMaster();
  clusterMessages.handle(`${MASTER_FAIL_WRITING_FILE}`, onFailWritingFileHandler).fromMaster();

  return {
    getFile,
    updateConfig,
  };
};

module.exports = messagesHandler;
